---
layout: post
title: "The Signal and the Noise"
book_title: "The Signal and the Noise"
book_author: "Nate Silver"
---

*The Signal and the Noise* was an ambitious book for me to start this project with--in part because it's over 450 pages long--but the timing was too perfect to ignore. In the same week that I decided to do this project, my dear friend Ma'ayan gifted me this book for my birthday, after having heard me rave about Nate Silver for months on end during this year's presidential election. I've followed Silver's blog [FiveThirtyEight](http://fivethirtyeight.blogs.nytimes.com/) since the 2008 presidential election. I was drawn to his emphasis on numbers and his blog posts that didn't shy away from the technical details of statistical analyis and were, seemingly, unassailable. This impression was vindicated repeatedly when Nate called the presidential elections in 2008 and 20012 almost state for state as well as a great many of the senatorial races in 2008, 2010, and 2012. I was eager to hear what he had to say about the state of prediction in our world.

When I first started reading, I will admit that I was a little disappointed. The book is not as tightly written and argued as his blog posts--which I often find to be flawless. He relies much more on evidence that is, more often than not, suggestive rather than definitive. In a way, though, this is fitting because a major theme of the book is uncertainty in the same way that the field of probability is about uncertainty. It's a book about how knowing what we don't know can help us make better decisions. And by the time I was three chapters in, when I was compelled to explain those first three chapters to a friend, I had to admit, I was learning.

The book's structure reminded me of Gladwell, in that it uses one interesting story after another from a variety of fields to build the book's core themes. Silver is not as talented a storyteller as Gladwell, but the trade-off is a fair one--his analysis of each field and anecdote is deeper, more factually-grounded, and more nuanced and complex than Gladwell could ever tackle. (Interestingly this, too, is a theme addressed in a chapter of the book--why people who are likely to make broad, far-reaching conclusions about the world are both more interesting to popular audiences *and* more likely to be wrong.) He covers a number of forecasting fields in-depth: weather, sports, gambling, earthquakes, and anticipating terror attacks, to name a few.

Narrowing this book down to a few takeaway bullet points is difficult, since part of the point of the book is that it's hard to understand the concepts involved in forecasting without spending some time dwelling in the world and mindset necessary to forecasting, but I'll attempt to spell out a few of the lessons that I think have the potential to change the way that I approach the world:

* There is no such thing as objective forecasting. All models incorportate our own biases into them. By pretending otherwise, we make worse forecasts. By acknowledging this, we can make better forecasts and get closer to the truth:

  > Some of you may be uncomfortable with a premise that I have been hinting at and will now state explicitly: we can *never* make perfectly objective predictions. They will *always* be tainted by our subjective point of view.                                                                                                                        
  >
  > But this book is emphatically against the nihilistic viewpoint that there is no objective truth. It asserts, rather, that a belief in objective truth—and a commitment to pursuing it—is the first prerequisite of making better predictions. The forecaster's next commitment is to realize that she perceives it imperfectly.
  
* Statistical significance is overrated; Bayesian analysis is underrated. Relatedly, people have a tendency to overvalue new information. A Bayesian approach to forecasting can temper this tendency.
  
  > Bayes's theorem does require us to think probabilistically about the world, even when it comes to issues we don't like to think of as being matters of chance. This does not require us to have taken the position that the world is intrinsically, *metaphysically* uncertain—Laplace thought everything from the orbits of the planets to the behavior of the smallest molecules was governed by orderly Newtonian rules, and yet he was instrumental in the development of Bayes's theorem. Rather, Bayes's theorem deals with *epistemological* uncertainty—the limits of our knowledge.

* More data can just as easily throw off your forecast as it can help it, if you don't think through how you utilize it.
  
  > This kind of statement is becoming more common in the age of Big Data. Who needs theory when you have so much information? But this is categorically the wrong attitude to take toward forecasting, especially in a field like economics where the data is so noisy. Statistical inferences are much stronger when backed up by theory or at least some deeper thinking about their root causes

* Expressing a range of probabilities rather than a single predictive value is critical to forecasting. After all, there is "an oft told joke: a statistician drowned crossing a river that was only three feet deep *on average*."

I am satisfied with having read this book, despite my initial misgivings. In the few days since reading it, I feel more intelligent in the way that I approach the world--an impression that I hope actually sticks around and bears fruit. I recommend this book to anyone who's interested in better ways of thinking about probability and how to anticipate events that are fraught with uncertainty.
